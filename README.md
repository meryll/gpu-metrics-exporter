# gpu-metrics-exporter
GPU metrics exporter for Prometheus - Python Client

Just deployed your deep learning python service using on GPU?
Have no idea what you are doing and GPU stuff is bascially black magic for you? 
Instead of hitting deploy and hoping for the best you can actually monitor live how you service is performing, how much GPU memory it's using (or not using if your service is using tensorflow-cpu instead of tensorflow-gpu). 

Python - Prometheus is super easy. 
And if you combine it with Grafana it can also be super pretty. 
